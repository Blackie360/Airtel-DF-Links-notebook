{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebe556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define file paths\n",
    "file_path = 'chat.csv'  # Updated to use the correct file name\n",
    "output_file = 'april_2025_chats.csv'\n",
    "\n",
    "# Read the CSV file with pandas\n",
    "df = pd.read_csv(file_path, header=None, names=['raw_data'], encoding='utf-8')\n",
    "\n",
    "# Extract date, time, and message using regex\n",
    "pattern = re.compile(r'(\\d{2}/\\d{2}/\\d{4}), (\\d{2}:\\d{2}) - (.+)')\n",
    "\n",
    "# Function to parse each row\n",
    "def parse_message(row):\n",
    "    match = pattern.search(row)\n",
    "    if match:\n",
    "        date, time, message = match.groups()\n",
    "        return pd.Series([date, time, message])\n",
    "    return pd.Series([None, None, None])\n",
    "\n",
    "# Apply parsing function\n",
    "extracted = df['raw_data'].apply(lambda x: parse_message(x) if isinstance(x, str) else pd.Series([None, None, None]))\n",
    "extracted.columns = ['date', 'time', 'message']\n",
    "\n",
    "# Combine with original dataframe\n",
    "df = pd.concat([df, extracted], axis=1)\n",
    "\n",
    "# Remove rows where date is None (parsing failed)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Convert date to datetime for easier filtering\n",
    "df['datetime'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Display the last 50 entries\n",
    "print(\"Last 50 entries:\")\n",
    "print(df.tail(50))\n",
    "\n",
    "# Filter for April data\n",
    "april_data = df[df['datetime'].dt.month == 4]\n",
    "\n",
    "# Save April data to new CSV file\n",
    "april_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"April data saved to {output_file}\")\n",
    "print(f\"Total messages: {len(df)}\")\n",
    "print(f\"April messages: {len(april_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff5106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Pattern for NET tickets\n",
    "net_pattern = re.compile(r'NET\\d+', re.IGNORECASE)\n",
    "\n",
    "# Pattern for link down reports from LNOC\n",
    "link_down_pattern = re.compile(r'link\\s+down|outage|connection\\s+lost', re.IGNORECASE)\n",
    "lnoc_pattern = re.compile(r'LNOC', re.IGNORECASE)\n",
    "\n",
    "# Prepare dataframe\n",
    "april_data = april_data.copy()  # Avoid SettingWithCopyWarning\n",
    "april_data['full_datetime'] = pd.to_datetime(april_data['date'] + ' ' + april_data['time'], format='%d/%m/%Y %H:%M')\n",
    "april_data_sorted = april_data.sort_values('full_datetime')\n",
    "\n",
    "unique_nets = {}\n",
    "link_down_reports = []\n",
    "\n",
    "# First pass: gather link down reports from LNOC\n",
    "for _, row in april_data_sorted.iterrows():\n",
    "    msg = row['message']\n",
    "    if isinstance(msg, str) and lnoc_pattern.search(msg) and link_down_pattern.search(msg):\n",
    "        link_down_reports.append({\n",
    "            'message': msg,\n",
    "            'full_datetime': row['full_datetime']\n",
    "        })\n",
    "\n",
    "# Extract NET tickets\n",
    "for _, row in april_data_sorted.iterrows():\n",
    "    msg = row['message']\n",
    "    if isinstance(msg, str):\n",
    "        tickets = net_pattern.findall(msg)\n",
    "        for ticket in tickets:\n",
    "            ticket_key = ticket.upper()\n",
    "            if ticket_key not in unique_nets:\n",
    "                # Find the nearest previous link down report\n",
    "                closest_report = None\n",
    "                closest_time_diff = None\n",
    "                for report in link_down_reports:\n",
    "                    if report['full_datetime'] < row['full_datetime']:\n",
    "                        time_diff = row['full_datetime'] - report['full_datetime']\n",
    "                        if closest_time_diff is None or time_diff < closest_time_diff:\n",
    "                            closest_time_diff = time_diff\n",
    "                            closest_report = report['message']\n",
    "                \n",
    "                unique_nets[ticket_key] = {\n",
    "                    'ticket': ticket_key,\n",
    "                    'date': row['date'],\n",
    "                    'time': row['time'],\n",
    "                    'link_down_report': closest_report,\n",
    "                    'time_since_report': str(closest_time_diff) if closest_time_diff else 'No prior report'\n",
    "                }\n",
    "\n",
    "# Convert to DataFrame\n",
    "nets_df = pd.DataFrame.from_dict(unique_nets.values())\n",
    "nets_df = nets_df.sort_values(['date', 'time'])\n",
    "\n",
    "if not nets_df.empty:\n",
    "    print(f\"Found {len(nets_df)} unique NET tickets in April 2025.\")\n",
    "    display(nets_df)\n",
    "    nets_df.to_csv(\"april_2025_nets.csv\", index=False)\n",
    "    print(\"Saved to april_2025_nets.csv\")\n",
    "else:\n",
    "    print(\"No NET tickets found in April 2025 data.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
